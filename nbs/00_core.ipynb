{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> This is where users start to interact with the underlying LLM and agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# install dependencies\n",
    "# %pip install replicate\n",
    "# %pip install gradio\n",
    "# %pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danc/Library/CloudStorage/GoogleDrive-cdan118@gmail.com/My Drive/Work/MachineLearning/SciAI/nbs/llm_QA.py:205: SyntaxWarning: invalid escape sequence '\\<'\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "# import langchain\n",
    "\n",
    "import os\n",
    "import llm_QA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "model = llm_QA.LLM(\"meta-llama\", \"TogetherAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language models (LLMs) are a type of artificial intelligence (AI) model that are designed to process and generate human-like language. They are a key area of research in natural language processing (NLP) and have been gaining significant attention in recent years.\n",
      "\n",
      "**What are large language models?**\n",
      "\n",
      "Large language models are neural networks that are trained on vast amounts of text data, such as books, articles, and online content. These models are designed to learn patterns and relationships in language, allowing them to generate text that is coherent, contextually relevant, and often indistinguishable from human-written text.\n",
      "\n",
      "**Key characteristics of large language models:**\n",
      "\n",
      "1. **Scale**: LLMs are trained on massive amounts of text data, often in the order of billions of parameters and hundreds of gigabytes of data.\n",
      "2. **Complexity**: LLMs are typically composed of multiple layers of neural networks, which allow them to capture complex patterns and relationships in language.\n",
      "3. **Self-supervised learning**: LLMs are trained using self-supervised learning techniques, where the model is trained to predict the next word in a sequence of text, rather than being explicitly taught to perform a specific task.\n",
      "4. **Generative capabilities**: LLMs can generate text that is coherent and contextually relevant, making them useful for applications such as language translation, text summarization, and chatbots.\n",
      "\n",
      "**Types of large language models:**\n",
      "\n",
      "1. **Transformers**: Transformers are a type of neural network architecture that are particularly well-suited for NLP tasks. They are widely used in LLMs and have been shown to achieve state-of-the-art results in many NLP tasks.\n",
      "2. **Recurrent neural networks (RNNs)**: RNNs are another type of neural network architecture that are commonly used in LLMs. They are particularly well-suited for modeling sequential data, such as text.\n",
      "3. **Hybrid models**: Some LLMs combine multiple architectures, such as transformers and RNNs, to leverage the strengths of each.\n",
      "\n",
      "**Applications of large language models:**\n",
      "\n",
      "1. **Language translation**: LLMs can be used to translate text from one language to another, often with high accuracy.\n",
      "2. **Text summarization**: LLMs can be used to summarize long pieces of text into shorter, more digestible versions.\n",
      "3. **Chatbots**: LLMs can be used to power chatbots that can engage in natural-sounding conversations with humans.\n",
      "4. **Content generation**: LLMs can be used to generate content, such as articles, social media posts, and even entire books.\n",
      "\n",
      "**Challenges and limitations:**\n",
      "\n",
      "1. **Data quality**: LLMs are only as good as the data they are trained on. Poor-quality data can lead to biased or inaccurate results.\n",
      "2. **Explainability**: LLMs can be difficult to interpret and understand, making it challenging to explain their decisions.\n",
      "3. **Adversarial attacks**: LLMs can be vulnerable to adversarial attacks, which can cause them to produce incorrect or misleading results.\n",
      "\n",
      "Overall, large language models have the potential to revolutionize many areas of NLP and have already achieved impressive results in a variety of applications. However, they also present significant challenges and limitations that must be addressed in order to fully realize their potential.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "# interact with the model directly to test\n",
    "messages = [\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"what are large language models?\"\n",
    "  }\n",
    "]\n",
    "\n",
    "response = model.get_llm_response(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# interact with the model directly to test multimodal inputs\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_local_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "display_local_image(\"images/a_colorful_llama_doing_ai_programming.jpeg\")\n",
    "\n",
    "import base64\n",
    "\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as img:\n",
    "    return base64.b64encode(img.read()).decode('utf-8')\n",
    "\n",
    "base64_image = encode_image(\"images/a_colorful_llama_doing_ai_programming.jpeg\")\n",
    "\n",
    "messages = [\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "      {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"describe the image!\"\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "          \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "]\n",
    "\n",
    "response = model.get_llm_response(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# A chatbot that allows users to interact with an LLM\n",
    "import gradio as gr\n",
    "\n",
    "def taskRouter(input, history):\n",
    "    prompt = input[\"text\"]\n",
    "    files = input[\"files\"]\n",
    "    messages = [history,\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = model.get_llm_response(messages)\n",
    "    #history = [messages, \n",
    "    #    {\n",
    "    #        \"role\": \"assistant\",\n",
    "    #        \"content\": response\n",
    "    #    }\n",
    "    #]\n",
    "    return response\n",
    "\n",
    "def vote(data: gr.LikeData):\n",
    "    if data.liked:\n",
    "        print(\"You upvoted this response: \" + data.value[\"value\"])\n",
    "    else:\n",
    "        print(\"You downvoted this response: \" + data.value[\"value\"])\n",
    "\n",
    "with gr.Blocks() as sciChat:\n",
    "    chatbot = gr.Chatbot(\n",
    "        height=300,\n",
    "        type=\"messages\",\n",
    "        placeholder=\"<strong>Your Personal Science AI Assistant</strong><br>Ask Me Anything\")\n",
    "    chatbot.like(vote, None, None)\n",
    "    gr.ChatInterface(\n",
    "        fn=taskRouter,\n",
    "        type=\"messages\",\n",
    "        chatbot=chatbot,\n",
    "        textbox=gr.MultimodalTextbox(placeholder=\"How can I help?\", container=False, scale=7),\n",
    "        title=\"SciAI Assistant\",\n",
    "        description=\"Ask me any question or carry out a task\",\n",
    "        theme=\"soft\",\n",
    "        examples=[{\"text\": \"Hello\", \"files\": []},{\"text\": \"What do you see in this image?\", \"files\": []}],\n",
    "        cache_examples=True,\n",
    "        multimodal=True\n",
    "    )\n",
    "    \n",
    "sciChat.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
